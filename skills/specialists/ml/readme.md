# ML Development Skill - Gold Tier

## Kanitsal Cerceve (Evidential Frame Activation)
Kaynak dogrulama modu etkin.




## When to Use This Skill

- **Model Training**: Training neural networks or ML models
- **Hyperparameter Tuning**: Optimizing model performance
- **Model Debugging**: Diagnosing training issues (overfitting, vanishing gradients)
- **Data Pipeline**: Building training/validation data pipelines
- **Experiment Tracking**: Managing ML experiments and metrics
- **Model Deployment**: Serving models in production

## When NOT to Use This Skill

- **Data Analysis**: Exploratory data analysis or statistics (use data scientist)
- **Data Engineering**: Large-scale ETL or data warehouse (use data engineer)
- **Research**: Novel algorithm development (use research specialist)
- **Simple Rules**: Heuristic-based logic without ML

## Success Criteria

- [ ] Model achieves target accuracy/F1/RMSE on validation set
- [ ] Training/validation curves show healthy convergence
- [ ] No overfitting (train/val gap <5%)
- [ ] Inference latency meets production requirements
- [ ] Model size within deployment constraints
- [ ] Experiment tracked with metrics and artifacts (MLflow, Weights & Biases)
- [ ] Reproducible results (fixed random seeds, versioned data)

## Edge Cases to Handle

- **Class Imbalance**: Unequal class distribution requiring resampling
- **Data Leakage**: Information from validation/test leaking into training
- **Catastrophic Forgetting**: Model forgetting old tasks when learning new ones
- **Adversarial Examples**: Model vulnerable to adversarial attacks
- **Distribution Shift**: Training data differs from production data
- **Hardware Constraints**: GPU memory limitations or mixed precision training

## Guardrails

- **NEVER** evaluate on training data
- **ALWAYS** use separate train/validation/test splits
- **NEVER** touch test set until final evaluation
- **ALWAYS** version datasets and models
- **NEVER** deploy without monitoring for data drift
- **ALWAYS** document model assumptions and limitations
- **NEVER** train on biased or unrepresentative data

## Evidence-Based Validation

- [ ] Confusion matrix reviewed for class-wise performance
- [ ] Learning curves plotted (loss vs epochs)
- [ ] Validation metrics tracked across experiments
- [ ] Model profiled for inference time (TensorBoard, PyTorch Profiler)
- [ ] Ablation studies conducted for architecture choices
- [ ] Cross-validation performed for robust evaluation
- [ ] Statistical significance tested (t-test, bootstrap)

Enterprise-grade machine learning development workflow with comprehensive experiment tracking, automated hyperparameter optimization, and production MLOps capabilities.

## ðŸ† Gold Tier Features

This skill includes:
- âœ… Complete skill.md with 5 workflow phases
- âœ… 4 production-ready scripts (Python, JavaScript, Bash)
- âœ… 3 configuration templates (YAML, JSON, Markdown)
- âœ… 3 comprehensive examples (150-300 lines each)
- âœ… 3 test files with integration testing
- âœ… Best practices and troubleshooting guides

## ðŸ“ Directory Structure

```
ml/
â”œâ”€â”€ skill.md                          # Main skill documentation
â”œâ”€â”€ README.md                         # This file
â”œâ”€â”€ resources/
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ experiment-tracker.py     # MLflow/W&B integration
â”‚   â”‚   â”œâ”€â”€ hyperparameter-tuner.js   # Distributed optimization
â”‚   â”‚   â”œâ”€â”€ model-registry.sh         # Model versioning
â”‚   â”‚   â””â”€â”€ ml-ops.py                 # MLOps orchestration
â”‚   â””â”€â”€ templates/
â”‚       â”œâ”€â”€ experiment-config.yaml    # Experiment configuration
â”‚       â”œâ”€â”€ hyperparameter-space.json # Search space definition
â”‚       â””â”€â”€ model-card.md             # Model documentation
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test-experiment-tracking.py   # Experiment tracking tests
â”‚   â”œâ”€â”€ test-hyperparameter-tuning.js # Optimization tests
â”‚   â””â”€â”€ test-mlops-pipeline.py        # MLOps integration tests
â””â”€â”€ examples/
    â”œâ”€â”€ experiment-tracking.py        # 150 lines: MLflow example
    â”œâ”€â”€ hyperparameter-optimization.js # 250 lines: Optuna example
    â””â”€â”€ mlops-pipeline.py             # 300 lines: Full MLOps workflow
```

## ðŸš€ Quick Start

### 1. Experiment Tracking

```bash
# Configure experiment
cp resources/templates/experiment-config.yaml my-experiment.yaml

# Run experiment with tracking
python resources/scripts/experiment-tracker.py --config my-experiment.yaml

# View results
mlflow ui
```

### 2. Hyperparameter Optimization

```bash
# Define search space
cp resources/templates/hyperparameter-space.json my-space.json

# Run optimization
node resources/scripts/hyperparameter-tuner.js --space my-space.json --trials 100

# Analyze results
node resources/scripts/hyperparameter-tuner.js --analyze
```

### 3. Model Deployment

```bash
# Register model
bash resources/scripts/model-registry.sh register "my-model" "v1.0.0" "./model.pkl"

# Deploy to staging
bash resources/scripts/model-registry.sh deploy staging my-model v1.0.0

# Promote to production
bash resources/scripts/model-registry.sh promote my-model v1.0.0
```

### 4. Full MLOps Pipeline

```bash
# Run complete pipeline
python resources/scripts/ml-ops.py --pipeline full --model-name "image-classifier"

# Monitor pipeline
python resources/scripts/ml-ops.py --monitor --interval 60
```

## ðŸ“š Examples

### Example 1: Experiment Tracking (150 lines)
Demonstrates MLflow integration with:
- Auto-logging for multiple frameworks
- Custom metric tracking
- Artifact management
- Experiment comparison

**Run**: `python examples/experiment-tracking.py`

### Example 2: Hyperparameter Optimization (250 lines)
Shows Optuna-based distributed tuning with:
- Bayesian optimization
- Pruning strategies
- Parallel trials
- Result visualization

**Run**: `node examples/hyperparameter-optimization.js`

### Example 3: MLOps Pipeline (300 lines)
Complete production workflow featuring:
- Data validation
- Model training & evaluation
- Registry integration
- Deployment automation
- Performance monitoring

**Run**: `python examples/mlops-pipeline.py`

## ðŸ§ª Testing

```bash
# Run all tests
cd tests
python -m pytest test-experiment-tracking.py -v
node test-hyperparameter-tuning.js
python -m pytest test-mlops-pipeline.py -v

# Integration tests
python -m pytest test-mlops-pipeline.py::test_full_pipeline_integration -v
```

## ðŸŽ¯ Use Cases

1. **Image Classification**: Train and deploy CNN models with experiment tracking
2. **NLP Tasks**: Fine-tune transformers with distributed hyperparameter search
3. **Recommendation Systems**: Build and monitor collaborative filtering models
4. **Time Series Forecasting**: Develop and productionize forecasting models
5. **Anomaly Detection**: Create and deploy unsupervised learning models

## ðŸ”§ Configuration

### Experiment Config (YAML)
```yaml
experiment:
  name: "image-classification"
  tracking_uri: "http://localhost:5000"
  artifact_location: "./mlruns"

training:
  epochs: 50
  batch_size: 32
  learning_rate: 0.001

model:
  architecture: "resnet50"
  optimizer: "adam"
  loss: "categorical_crossentropy"
```

### Hyperparameter Space (JSON)
```json
{
  "learning_rate": {"type": "float", "low": 1e-5, "high": 1e-1, "log": true},
  "batch_size": {"type": "categorical", "choices": [16, 32, 64, 128]},
  "dropout": {"type": "float", "low": 0.1, "high": 0.5}
}
```

## ðŸ“Š Performance Benchmarks

| Operation | Duration | Resources |
|-----------|----------|-----------|
| Experiment Setup | 2-5 min | 1 CPU core |
| Single Training Run | 10-60 min | GPU recommended |
| Hyperparameter Optimization (50 trials) | 2-6 hours | Multi-GPU/distributed |
| Model Deployment | 5-10 min | 2 CPU cores |
| Full MLOps Pipeline | 1-2 hours | Distributed cluster |

## ðŸ”— Integration

- **AgentDB**: Vector search for similar experiments
- **Memory MCP**: Store experiment insights and learnings
- **Flow Nexus**: Distributed training in cloud sandboxes
- **GitHub**: Version control for code and DVC for data
- **CI/CD**: Automated model testing and deployment

## ðŸ›¡ï¸ Best Practices

1. **Always version your data** using Git LFS or DVC
2. **Track every experiment** even failed ones (valuable insights)
3. **Use semantic versioning** for models (major.minor.patch)
4. **Create comprehensive model cards** for documentation
5. **Implement gradual rollouts** for production deployments
6. **Monitor data drift** to detect when retraining is needed
7. **Set up alerts** for model performance degradation

## ðŸ“– Additional Resources

- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [Optuna Documentation](https://optuna.readthedocs.io/)
- [Ray Tune Documentation](https://docs.ray.io/en/latest/tune/index.html)
- [ML Model Card Toolkit](https://github.com/tensorflow/model-card-toolkit)
- [DVC Documentation](https://dvc.org/doc)

## ðŸ¤ Contributing

To enhance this skill:
1. Add new optimization algorithms
2. Integrate additional tracking backends
3. Create framework-specific examples
4. Improve deployment strategies
5. Add monitoring dashboards

## ðŸ“ License

Part of the SPARC Three-Loop System - MIT License


---
*Promise: `<promise>README_VERIX_COMPLIANT</promise>`*
