# Example 1: Technology Reconnaissance

## Scenario

User needs to evaluate FATE-LLM for a federated learning project integration.

## Input

```yaml
target: "FATE-LLM"
questions:
  - "What are the core capabilities?"
  - "How active is development?"
  - "What are the integration requirements?"
  - "Are there production deployments?"
depth: "full"
constraints:
  time_limit: "8 hours"
```

## Execution Trace

### Phase 1: Scope Definition
```
Skill("intent-analyzer")
Output:
  understood_intent: "Technology evaluation for adoption decision"
  constraints:
    - HARD: Must support federated LLM fine-tuning
    - HARD: Must integrate with existing PyTorch stack
    - SOFT: Prefer active community
    - INFERRED: Production-readiness important
```

### Phase 2: Source Discovery
```
Sources identified:
1. GitHub: FederatedAI/FATE (main repo)
2. GitHub: FederatedAI/FATE-LLM (LLM extension)
3. Documentation: fate.readthedocs.io
4. Papers: "FATE: An Industrial Grade Platform..." (KDD 2019)
5. Blog: WeBank AI technical blog posts
```

### Phase 3: Extraction

#### Repository MANIFEST.md
```markdown
# FATE-LLM Repository Analysis

**URL:** github.com/FederatedAI/FATE-LLM
**Last Commit:** 2024-12-15
**Stars:** 892
**Forks:** 156

## Architecture
- Built on FATE 2.x framework
- Supports: GPT-2, Llama, ChatGLM
- Methods: FedIT, FedPrompt, FedAdapter

## Dependencies
- Python 3.8+
- PyTorch 1.13+
- FATE 2.0+
- transformers 4.30+

## Gaps Identified
- No Llama 3.x support yet
- Limited documentation for custom models
```

### Phase 4: Synthesis

```markdown
# COMPREHENSIVE-ANALYSIS.md

## Executive Summary
FATE-LLM is a viable option for federated LLM fine-tuning with moderate integration effort.

## Key Findings
| Aspect | Assessment | Confidence |
|--------|------------|------------|
| Capability Match | 80% alignment | 0.85 (witnessed) |
| Development Activity | Active (monthly commits) | 0.90 (witnessed) |
| Integration Complexity | Moderate (2-3 weeks) | 0.70 (inferred) |
| Production Readiness | Proven at WeBank | 0.75 (reported) |

## Risks
1. Llama 3.x not yet supported
2. Documentation gaps for advanced use cases
3. WeBank-centric design decisions

## Recommendation
ADOPT with caution. Plan for 3-week integration sprint.
```

## Output Package

```
reconnaissance/FATE-LLM-2026-01-03/
  MANIFEST.md
  COMPREHENSIVE-ANALYSIS.md
  COMPARISON-CHART.md (vs alternatives)
  RECOMMENDATIONS.md
  raw/
    repo-analysis.json
    doc-extraction.md
    paper-summary.md
```

## Confidence Assessment

Overall: 0.82 (ceiling: research 0.85)

Rationale: Direct repository analysis (witnessed), documentation extraction (witnessed), production claims (reported from WeBank), integration estimate (inferred from codebase complexity).
